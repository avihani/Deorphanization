{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "1.20.3\n",
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import statistics\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_aa = ['S','R','L','P','T','A',\n",
    "                'V','G','I','F','Y','C',\n",
    "                'H','Q','N','K','D','E',\n",
    "                'M','W','-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps6_dir = \"./olfr_de/\"\n",
    "\n",
    "filename_cid = pd.read_csv(\"./cid_info/filename_cid.csv\", index_col = 0)\n",
    "filename_cid = filename_cid.to_dict(orient='index')\n",
    "\n",
    "for filename in filename_cid:\n",
    "    filename_cid[filename]['cid'] = str(filename_cid[filename]['cid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "odor_test_count = {}\n",
    "\n",
    "for base_name in filename_cid:\n",
    "    split_name = base_name.split('_')[2:]\n",
    "    odor_name = split_name[1].split('.')[0]\n",
    "    if odor_name not in odor_test_count:\n",
    "        odor_test_count[odor_name] = 0\n",
    "    odor_test_count[odor_name] += 1\n",
    "    \n",
    "multi_conc_tested = {}\n",
    "\n",
    "for ps6ip_file in os.listdir(ps6_dir):\n",
    "    conc_odor = ps6ip_file.split('_')[2:]\n",
    "    conc = conc_odor[0]\n",
    "    odor_name = conc_odor[1].split('.')[0]\n",
    "    if odor_test_count[odor_name] > 1:\n",
    "        ps6ip_file = os.path.join(ps6_dir, ps6ip_file)\n",
    "        df = pd.read_csv(ps6ip_file, index_col = 0)\n",
    "        if odor_name not in multi_conc_tested:\n",
    "            multi_conc_tested[odor_name] = {}\n",
    "        multi_conc_tested[odor_name][conc] = df\n",
    "\n",
    "multi_conc_activation = {}\n",
    "\n",
    "for odor in multi_conc_tested:\n",
    "    if odor not in multi_conc_activation:\n",
    "        multi_conc_activation[odor] = {}\n",
    "    for conc in multi_conc_tested[odor]:\n",
    "        df = multi_conc_tested[odor][conc]\n",
    "        sig_or_count = df[(df.logFC > 0) & (df.FDR < 0.05)].shape[0]\n",
    "        if sig_or_count < 8:\n",
    "            continue\n",
    "        multi_conc_activation[odor][conc] = sig_or_count\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_resp = {}\n",
    "sigOR_dict = {}\n",
    "nonsigOR_dict = {}\n",
    "\n",
    "for odor in odor_test_count:\n",
    "    #Pick out concentration for odors tested at multiple concentrations\n",
    "    if odor_test_count[odor] > 1:\n",
    "        fewest_or_conc = min(multi_conc_activation[odor], key=multi_conc_activation[odor].get)\n",
    "        filename = \"pS6_DE_\"+fewest_or_conc+\"_\"+odor+\".csv\"\n",
    "    else:\n",
    "    #Rest which are tested at a single concentration\n",
    "        for base_file in os.listdir(ps6_dir):\n",
    "            odor_name = base_file.split('_')[3].split('.')[0]\n",
    "            if odor == odor_name:\n",
    "                filename = base_file\n",
    "    file_path = os.path.join(ps6_dir, filename)\n",
    "    cid = str(filename_cid[filename]['cid'])\n",
    "    df = pd.read_csv(file_path, index_col = 0)\n",
    "    df = df.loc[:,['symbol','logFC','FDR']]\n",
    "    df = df.sort_values(by=['symbol'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    if df[(df.logFC > 0) & (df.FDR < 0.05)].shape[0] == 0:\n",
    "        continue\n",
    "    if df[(df.logFC > 0) & (df.FDR < 0.05)].shape[0] >= 100:\n",
    "        continue\n",
    "    sigORs = df[((df.FDR < 0.05) & (df.logFC > 0))]\n",
    "    nonsigORs = df[((df.FDR >= 0.25) | (df.logFC < 0))]\n",
    "    sigOR_dict[cid] = []\n",
    "    nonsigOR_dict[cid] = []\n",
    "    sigOR_dict[cid].extend(sigORs['symbol'].values.tolist())\n",
    "    nonsigOR_dict[cid].extend(nonsigORs['symbol'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(data, filepath):\n",
    "    with open(filepath, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as infile:\n",
    "        data = json.load(infile)\n",
    "    return data\n",
    "\n",
    "def load_grantham(granthamfile):\n",
    "    \"\"\"\n",
    "    Input: Grantham scores table, long format\n",
    "    Output: Grantham scores dictionary\n",
    "    \"\"\"\n",
    "    grantham_dict = {}\n",
    "    with open(granthamfile, 'r') as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            line = line.split(',')\n",
    "            if line[0] not in grantham_dict:\n",
    "                grantham_dict[line[0]]={}\n",
    "            grantham_dict[line[0]][line[1]] = int(line[2])\n",
    "    return grantham_dict\n",
    "\n",
    "def read_fasta(fastafile):\n",
    "    \"\"\"\n",
    "    Input: FASTA file of aligned Olfr (gaps OK)\n",
    "           entries must start with '>' & sequence must be immediately next\n",
    "           no other lines allowed\n",
    "    Output: dictionary with keys equal identity of entry\n",
    "            values are aa sequence associated with entry \n",
    "    \"\"\"\n",
    "    fasta_dict = {}\n",
    "    header = ''\n",
    "    sequence = ''\n",
    "    with open(fastafile, 'r') as f:\n",
    "        for line in f:\n",
    "            if '>' in line:\n",
    "                if sequence != '':\n",
    "                    fasta_dict[header] = sequence\n",
    "                header = line[1:].strip('\\n')\n",
    "                sequence = ''\n",
    "            else: \n",
    "                sequence += line.strip('\\n')\n",
    "        fasta_dict[header] = sequence\n",
    "    return fasta_dict\n",
    "\n",
    "def alignment_info(fasta_dict):\n",
    "    \"\"\"\n",
    "    Input: FASTA dictionary with gaps\n",
    "    Output: FASTA dictionary with original amino acid + position\n",
    "    \"\"\"\n",
    "    alignment_info = {}\n",
    "    for entry in fasta_dict:\n",
    "        alignment_info[entry] = {}\n",
    "        counter = 0\n",
    "        for position, aa in enumerate(fasta_dict[entry]):\n",
    "            if aa != '-':\n",
    "                counter += 1\n",
    "                alignment_info[entry][position+1] = aa+'_'+str(counter)\n",
    "            else:\n",
    "                alignment_info[entry][position+1] = aa\n",
    "    return alignment_info\n",
    "\n",
    "def remove_gaps(fasta_dict):\n",
    "    \"\"\"\n",
    "    Input: FASTA dictionary with gaps\n",
    "    Output: FASTA dictionary with gaps removed\n",
    "    \"\"\"\n",
    "    no_gaps = {}\n",
    "    for entry in fasta_dict:\n",
    "        seq = fasta_dict[entry]\n",
    "        seq = re.sub('-','',seq)\n",
    "        no_gaps[entry] = seq\n",
    "    return no_gaps\n",
    "\n",
    "def write_fasta(fasta_dict, file_path):\n",
    "    \"\"\"\n",
    "    Input: FASTA dictionary, path to write to\n",
    "    Output: FASTA file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as outfile:\n",
    "        for key in fasta_dict:\n",
    "            outfile.write('{0}\\n{1}\\n'.format(\">\"+key, fasta_dict[key]))\n",
    "\n",
    "def gap_calculator(fastafile):\n",
    "    \"\"\"\n",
    "    Input: FASTA file\n",
    "    Output: Percentage of gaps at each position\n",
    "    \"\"\"\n",
    "    percent_gap = {}\n",
    "    for position in fastafile:\n",
    "        aa_count = 0\n",
    "        gap_count = 0\n",
    "        for residue in fastafile[position]:\n",
    "            if residue == '-':\n",
    "                gap_count += fastafile[position][residue]\n",
    "            else:\n",
    "                aa_count += fastafile[position][residue]\n",
    "        percent_gap[position] = (gap_count/(gap_count+aa_count))*100\n",
    "    return percent_gap\n",
    "                        \n",
    "def aa_composition(aligned_fasta):\n",
    "    \"\"\"\n",
    "    Input: Aligned FASTA with gaps\n",
    "    Output: Amino acid composition at all positions\n",
    "    \"\"\"\n",
    "    consus = {}\n",
    "    for key in aligned_fasta:\n",
    "        for position, aa in enumerate(aligned_fasta[key]):\n",
    "            consus[position] = {}\n",
    "    for position in consus:\n",
    "        for aa_possibility in alignment_aa:\n",
    "            consus[position][aa_possibility] = 0\n",
    "    for key in aligned_fasta:\n",
    "        for position, aa in enumerate(aligned_fasta[key]):\n",
    "            consus[position][aa] += 1\n",
    "    return consus\n",
    "\n",
    "def length_calculator(percent_gaps):\n",
    "    \"\"\"\n",
    "    Input: Percent gaps per position\n",
    "    Output: How sequence length changes as a function of percent gaps\n",
    "    \"\"\"\n",
    "    seq_length = {}\n",
    "    align_length = len(percent_gaps)\n",
    "    for gap_occupancy in range(101):\n",
    "        counter = 0\n",
    "        for position in percent_gaps:\n",
    "            if percent_gaps[position] > gap_occupancy :\n",
    "                counter += 1\n",
    "        seq_length[100-gap_occupancy] = align_length - counter\n",
    "    return seq_length\n",
    "\n",
    "def full_distances(aligned_fasta, grantham_vals, avg_grantham):\n",
    "    \"\"\"\n",
    "    Input: Aligned FASTA file with gaps & grantham scores\n",
    "    Output: Full grantham distance between entries\n",
    "    \"\"\"\n",
    "    distances = {}\n",
    "    for key1 in aligned_fasta:\n",
    "        distances[key1] = {}\n",
    "        for key2 in aligned_fasta:\n",
    "            distances[key1][key2] = 0\n",
    "    for key1 in distances:\n",
    "        for key2 in distances[key1]:\n",
    "            if key2 == key1:\n",
    "                continue\n",
    "            for position, residue in enumerate(aligned_fasta[key1]):\n",
    "                aa1 = aligned_fasta[key1][position]\n",
    "                aa2 = aligned_fasta[key2][position]\n",
    "                if aa1 == '-' and aa2 == '-':\n",
    "                    distances[key1][key2] += 0\n",
    "                elif aa1 != '-' and aa2 != '-':\n",
    "                    distances[key1][key2] += grantham_vals[aa1][aa2]\n",
    "                else:\n",
    "                    #impute average Grantham for this position\n",
    "                    distances[key1][key2] += float(avg_grantham[str(position)]) \n",
    "    return distances\n",
    "\n",
    "def average_grantham(aligned_fasta, grantham_vals):\n",
    "    \"\"\"\n",
    "    Input: Aligned FASTA file with gaps & grantham scores\n",
    "    Output: Calculates average pairwise grantham score at\n",
    "    each position.\n",
    "    \"\"\"\n",
    "    consus = {}\n",
    "    for key in aligned_fasta:\n",
    "        for position, aa in enumerate(aligned_fasta[key]):\n",
    "            if position not in consus:\n",
    "                consus[position] = []\n",
    "            consus[position].append(aa)        \n",
    "    avg_consus = {}\n",
    "    for position in consus:\n",
    "        length = 0\n",
    "        sum_grantham = 0\n",
    "        aa_list = consus[position]\n",
    "        for aa1, aa2 in itertools.combinations(aa_list, 2):\n",
    "            if aa1 != '-' and aa2 != '-': \n",
    "                length += 1\n",
    "                sum_grantham += grantham_vals[aa1][aa2]\n",
    "        if length == 0:\n",
    "            length = 1\n",
    "        avg_consus[position] = sum_grantham/length\n",
    "    return avg_consus\n",
    "\n",
    "def get_seqs(sig_or_dict, aligned_fasta):\n",
    "    \"\"\"\n",
    "    Input: Dictionary of receptors significant responding to some odors\n",
    "    Output: Sequences of significantly activated receptors if they are in the alignment file\n",
    "    \"\"\"\n",
    "    sig_seq = {}\n",
    "    for odor in sig_or_dict:\n",
    "        sig_seq[odor] = {}\n",
    "        for sig_rec in sig_or_dict[odor]:\n",
    "            if sig_rec in aligned_fasta:\n",
    "                sig_seq[odor][sig_rec] = aligned_fasta[sig_rec]\n",
    "    return sig_seq\n",
    "\n",
    "def get_grantham_dist(sig_sequences, grantham_vals, avg_grantham):\n",
    "    \"\"\"\n",
    "    Input: Sequences dictionary, grantham dictionary, avg grantham scores\n",
    "    Output: Generates a dictionary for the grantham score distribution at each position\n",
    "    \"\"\"\n",
    "    sig_grantham_distance = {}\n",
    "    for odor in sig_sequences:\n",
    "        sig_grantham_distance[odor] = {}\n",
    "        for rec1, rec2 in itertools.combinations(sig_sequences[odor], 2):\n",
    "            for position, aa in enumerate(sig_sequences[odor][rec1]):\n",
    "                aa1 = sig_sequences[odor][rec1][position]\n",
    "                aa2 = sig_sequences[odor][rec2][position]\n",
    "                if position not in sig_grantham_distance[odor]:\n",
    "                    sig_grantham_distance[odor][position] = []\n",
    "                if aa1 != '-' and aa2 != '-':\n",
    "                    sig_grantham_distance[odor][position].append(grantham_vals[aa1][aa2])\n",
    "                elif aa1 == '-' and aa2 == '-':\n",
    "                    sig_grantham_distance[odor][position].append(0)\n",
    "                else:\n",
    "                    sig_grantham_distance[odor][position].append(avg_grantham[str(position)])\n",
    "    return sig_grantham_distance\n",
    "\n",
    "def Average(lst):\n",
    "    \"\"\"\n",
    "    Input:list\n",
    "    Output: Average value of list\n",
    "    \"\"\"\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def delta_length_calc(gap_length_estimate, increment):\n",
    "    \"\"\"\n",
    "    Input: Gap length estimate dictionary & increment check\n",
    "    Output: How much the length changes as a function of amino\n",
    "    acid occupancy\n",
    "    \"\"\"\n",
    "    delta_length = {}\n",
    "    for gap_occ in range(0,100,increment):\n",
    "        current_length = gap_length_estimate[gap_occ]\n",
    "        new_length = gap_length_estimate[gap_occ+increment]\n",
    "        length_change = current_length-new_length\n",
    "        delta_length[gap_occ+increment] = length_change\n",
    "    return delta_length\n",
    "\n",
    "def gaps_removed(aligned_fasta, percent_gaps, gap_occupancy_cutoff):\n",
    "    \"\"\"\n",
    "    Input: Aligned FASTA file. Percent gaps per position. Cutoff for gaps per position.\n",
    "    Output: New FASTA file with positions with more gaps than the cutoff removed.\n",
    "    \"\"\"\n",
    "    marked_fasta_dict = {}\n",
    "    for olfr in aligned_fasta:\n",
    "        orig_seq = list(aligned_fasta[olfr])\n",
    "        for position,aa in enumerate(aligned_fasta[olfr]):\n",
    "            if percent_gaps[position] > gap_occupancy_cutoff:\n",
    "                orig_seq[position] = '*'\n",
    "        new_seq = \"\".join(orig_seq)\n",
    "        marked_fasta_dict[olfr] = new_seq\n",
    "    new_fasta_dict = {}\n",
    "    for olfr in marked_fasta_dict:\n",
    "        orig_seq = marked_fasta_dict[olfr]\n",
    "        new_seq = re.sub('[*]','',orig_seq)\n",
    "        new_fasta_dict[olfr] = new_seq\n",
    "    return new_fasta_dict\n",
    "\n",
    "   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mod_info(aligned_fasta, marked_fasta_dict, gap_occupancy_cutoff):\n",
    "    \"\"\"\n",
    "    Input: Original FASTA alignment dictionary & modified alignment with gaps removed.\n",
    "    The gap occupancy cutoff value should be the same as fxn(gaps_removed).\n",
    "    Output: Dictionary with positions of original protein & modified sequence.\n",
    "    \"\"\"\n",
    "    marked_fasta_dict = {}\n",
    "    for olfr in aligned_fasta:\n",
    "        orig_seq = list(aligned_fasta[olfr])\n",
    "        for position,aa in enumerate(aligned_fasta[olfr]):\n",
    "            if percent_gaps[position] > gap_occupancy_cutoff:\n",
    "                orig_seq[position] = '*'\n",
    "        new_seq = \"\".join(orig_seq)\n",
    "        marked_fasta_dict[olfr] = new_seq\n",
    "    refined_dict = {}\n",
    "    for olfr in aligned_fasta:\n",
    "        refined_dict[olfr] = {}\n",
    "        prot_position = 0\n",
    "        mod_position = 0\n",
    "        for position,aa in enumerate(aligned_fasta[olfr]):\n",
    "            if aligned_fasta[olfr][position] != '-':\n",
    "                prot_position += 1\n",
    "            if marked_fasta_dict[olfr][position] != '*' and aligned_fasta[olfr][position] != '-':\n",
    "                mod_position += 1\n",
    "            if marked_fasta_dict[olfr][position] != '*' and aligned_fasta[olfr][position] == '-':\n",
    "                mod_position += 1\n",
    "            #write data\n",
    "            if aa == '-' and marked_fasta_dict[olfr][position] != '-':\n",
    "                refined_dict[olfr][position+1] = \"-\"\n",
    "            elif aa == '-' and marked_fasta_dict[olfr][position] == '-':\n",
    "                refined_dict[olfr][position+1] = \"prot_position: GAP, mod_position: GAP\"\n",
    "            elif aa != '-' and marked_fasta_dict[olfr][position] == '*':\n",
    "                refined_dict[olfr][position+1] = \"prot_position: \"+str(prot_position)+\",\"+\" mod_position: REMOVED\"\n",
    "            else:\n",
    "                refined_dict[olfr][position+1] = \"prot_position: \"+str(prot_position)+\",\"+\" mod_position: \"+str(mod_position)\n",
    "    return refined_dict\n",
    "            \n",
    "def extract_info(fasta_60p_info, info_type):\n",
    "    \"\"\"\n",
    "    Input: FASTA info dictionary.\n",
    "    Info type = 0 retrieves position in original aa sequence.\n",
    "    Info type = 1 retrieves position in attenuated aa sequence after removing low aa positions.\n",
    "    Output: Dictionary with position info.\n",
    "    \"\"\"\n",
    "    prot_position = {}\n",
    "    for olfr in fasta_60p_info:\n",
    "        prot_position[olfr] = {}\n",
    "        for position in fasta_60p_info[olfr]:\n",
    "            info = fasta_60p_info[olfr][position]\n",
    "            if info == '-':\n",
    "                prot_position[olfr][position] = \"-\"\n",
    "            else:\n",
    "                prot_position[olfr][position] = fasta_60p_info[olfr][position].split(',')[info_type].split(':')[1].strip(' ')\n",
    "    return prot_position\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_nr(input_odor, input_receptor, input_distance):\n",
    "    \"\"\"\n",
    "    Dependent data structure: \n",
    "    Input: For a given odor, receptor, and it's distance to another receptor...\n",
    "    Output: Find the nearest nonresponding receptor based on full length distnaces.\n",
    "    Output is a tuple of 2:\n",
    "        [0] = Nearest non-responding receptor\n",
    "        [1] = Nearest non-responding receptor distance to input receptor\n",
    "    \"\"\"\n",
    "    nearest_nr = min({k:v for k,v in olfr_distances_60p_aaIdentity[input_receptor].items()\n",
    "                     if k in non_sig_sequences_60p_aaIdentity[input_odor].keys()}.items(),\n",
    "                    key=lambda e: abs(input_distance-e[1]))\n",
    "    return nearest_nr\n",
    "\n",
    "#Odors 10925, 8094, 440917 have only 1 responding receptor\n",
    "#Pairwise analysis of receptors cannot be done for these odors\n",
    "def make_nearest_nr_dict(input_dict):\n",
    "    \"\"\"\n",
    "    Dependent data structure: olfr_distances_60p_aaIdentity\n",
    "    Dependent function: find_nearest_nr\n",
    "    Input: sig_sequences_60p_aaIdentity\n",
    "    Output: Dictionary with the following structure\n",
    "        [0] = [odor]\n",
    "        [1] = [responding receptor 1, comparing from]\n",
    "        [2] = [responding receptor 2, comparing to]\n",
    "        [3] = [(nearest non-responding receptor, distance to nearest non-responder)]\n",
    "              based on distance between responding receptor 1 & responding receptor 2\n",
    "    \"\"\"\n",
    "    nearest_nr_dict = {}\n",
    "    for odor in input_dict:\n",
    "        nearest_nr_dict[odor] = {}\n",
    "        for olfr1, olfr2 in itertools.combinations(input_dict[odor].keys(), 2):\n",
    "            distance_val = olfr_distances_60p_aaIdentity[olfr1][olfr2]\n",
    "            nearest_nr_olfr1 = find_nearest_nr(odor, olfr1, distance_val)\n",
    "            nearest_nr_olfr2 = find_nearest_nr(odor, olfr2, distance_val)\n",
    "            if olfr1 not in nearest_nr_dict[odor]:\n",
    "                nearest_nr_dict[odor][olfr1] = {}\n",
    "            if olfr2 not in nearest_nr_dict[odor]:\n",
    "                nearest_nr_dict[odor][olfr2] = {}\n",
    "            nearest_nr_dict[odor][olfr1][olfr2] = nearest_nr_olfr1[0], nearest_nr_olfr1[1]\n",
    "            nearest_nr_dict[odor][olfr2][olfr1] = nearest_nr_olfr2[0], nearest_nr_olfr2[1]\n",
    "    return nearest_nr_dict\n",
    "\n",
    "def convergent_distances(input_dict):\n",
    "    \"\"\"\n",
    "    Input: nearest_nr_dict_60p_aaIdentity\n",
    "    Output: Dictionary for list of grantham distances at each position between amino\n",
    "    acids of responding receptors and nearest non-responder based on full length sequence\n",
    "    distnace.\n",
    "    \"\"\"\n",
    "    conv_evolve_dist_60p_aaIdentity = {}\n",
    "    for odor in input_dict:\n",
    "        conv_evolve_dist_60p_aaIdentity[odor] = {}\n",
    "        for resp1 in input_dict[odor]:\n",
    "            resp1_seq = fasta_60p_aaIdentity[resp1]\n",
    "            for resp2 in input_dict[odor][resp1]:\n",
    "                nonresp = input_dict[odor][resp1][resp2][0]\n",
    "                nonresp_seq = fasta_60p_aaIdentity[nonresp]\n",
    "                for position, resp_aa in enumerate(resp1_seq):\n",
    "                    nonresp_aa = nonresp_seq[position]\n",
    "                    if position not in conv_evolve_dist_60p_aaIdentity[odor]:\n",
    "                        conv_evolve_dist_60p_aaIdentity[odor][position] = []\n",
    "                    if resp_aa == '-' and nonresp_aa == '-':\n",
    "                        gd = 0\n",
    "                    elif resp_aa != '-' and nonresp_aa != '-':\n",
    "                        gd = grantham_vals[resp_aa][nonresp_aa]\n",
    "                    else:\n",
    "                        gd = avg_grantham_60p_aaIdentity[str(position)]\n",
    "                    conv_evolve_dist_60p_aaIdentity[odor][position].append(gd)\n",
    "    return conv_evolve_dist_60p_aaIdentity\n",
    "                \n",
    "def ks_test(dict1, dict2):\n",
    "    ks_out = {}\n",
    "    for odor in dict1:\n",
    "        if len(dict1[odor]) == 0:\n",
    "            continue\n",
    "        ks_out[odor] = {}\n",
    "        for position in dict1[odor]:\n",
    "            lst1 = dict1[odor][position]\n",
    "            lst2 = dict2[odor][position]\n",
    "            ks_results = ks_2samp(lst1, lst2)\n",
    "            ks_out[odor][position] = ks_results[0], ks_results[1]\n",
    "    return ks_out               \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_fasta = read_fasta(\"./mouseOR_alignment/mouseOR_alignment.fasta\")\n",
    "grantham_vals = load_grantham(\"./mouseOR_alignment/grantham_table.csv\")\n",
    "fasta_composition = aa_composition(aligned_fasta)\n",
    "percent_gaps = gap_calculator(fasta_composition)\n",
    "fasta_info = alignment_info(aligned_fasta)\n",
    "gap_length_estimate = length_calculator(percent_gaps)\n",
    "delta_length = delta_length_calc(gap_length_estimate, 5)\n",
    "#avg_grantham = average_grantham(aligned_fasta, grantham_vals)\n",
    "#write_json(avg_grantham, \"./mouseOR_alignment/avg_grantham.json\")\n",
    "avg_grantham = load_json(\"./mouseOR_alignment/avg_grantham.json\")\n",
    "#olfr_distances = full_distances(aligned_fasta, grantham_vals, avg_grantham)\n",
    "#olfr_distances = pd.DataFrame.from_dict(olfr_distances)\n",
    "#olfr_distances.to_csv(\"./mouseOR_alignment/OR_distances.csv\")\n",
    "olfr_distances = pd.read_csv(\"./mouseOR_alignment/OR_distances.csv\", index_col = 0).to_dict()\n",
    "sig_sequences = get_seqs(sigOR_dict, aligned_fasta)\n",
    "non_sig_sequences = get_seqs(nonsigOR_dict, aligned_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_60p_aaIdentity = gaps_removed(aligned_fasta, percent_gaps, 40)\n",
    "sig_sequences_60p_aaIdentity = get_seqs(sigOR_dict, fasta_60p_aaIdentity)\n",
    "non_sig_sequences_60p_aaIdentity = get_seqs(nonsigOR_dict, fasta_60p_aaIdentity)\n",
    "fasta_60p_info = extract_mod_info(aligned_fasta, fasta_60p_aaIdentity, 40)\n",
    "orig_prot_position = extract_info(fasta_60p_info, 0)\n",
    "mod_prot_position = extract_info(fasta_60p_info, 1)\n",
    "fasta_composition_60p_aaIdentity = aa_composition(fasta_60p_aaIdentity)\n",
    "#avg_grantham_60p_aaIdentity = average_grantham(fasta_60p_aaIdentity, grantham_vals)\n",
    "#write_json(avg_grantham_60p_aaIdentity, \"./mouseOR_alignment/avg_grantham_60p_aaIdentity.json\")\n",
    "avg_grantham_60p_aaIdentity = load_json(\"./mouseOR_alignment/avg_grantham_60p_aaIdentity.json\")\n",
    "#olfr_distances_60p_aaIdentity = full_distances(fasta_60p_aaIdentity, grantham_vals, avg_grantham_60p_aaIdentity)\n",
    "#write_json(olfr_distances_60p_aaIdentity, \"./mouseOR_alignment/olfr_distances_60p_aaIdentity.json\")\n",
    "olfr_distances_60p_aaIdentity = load_json(\"./mouseOR_alignment/olfr_distances_60p_aaIdentity.json\")\n",
    "#pd.DataFrame.from_dict(olfr_distances_60p_aaIdentity).to_csv(\"./mouseOR_alignment/olfr_distances_60p_aaIdentity.csv\")\n",
    "nearest_nr_dict_60p_aaIdentity = make_nearest_nr_dict(sig_sequences_60p_aaIdentity)\n",
    "#Compute pairwise distances between responding receptors for every position in every odor\n",
    "sig_grantham_dist_60p_aaIdentity = get_grantham_dist(sig_sequences_60p_aaIdentity, grantham_vals, avg_grantham_60p_aaIdentity)\n",
    "#Compute pairwise distances between responding receptors & nearest non-responders\n",
    "#for every position in every odor\n",
    "conv_nr_distances_60p_aaIdentity = convergent_distances(nearest_nr_dict_60p_aaIdentity)\n",
    "#Kolmogorov-smirnov statistical test\n",
    "ks_60p_aaIdentity = ks_test(sig_grantham_dist_60p_aaIdentity, conv_nr_distances_60p_aaIdentity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_60p_pval = {}\n",
    "\n",
    "for odor in ks_60p_aaIdentity:\n",
    "    ks_60p_pval[odor] = {}\n",
    "    for position in ks_60p_aaIdentity[odor]:\n",
    "        ks_60p_pval[odor][position] = ks_60p_aaIdentity[odor][position][1]\n",
    "\n",
    "\n",
    "ks_count = {}\n",
    "\n",
    "for odor in ks_60p_aaIdentity:\n",
    "    for position in ks_60p_aaIdentity[odor]:\n",
    "        if position not in ks_count:\n",
    "            ks_count[position] = 0\n",
    "        if ks_60p_aaIdentity[odor][position][1] < 0.05:\n",
    "            ks_count[position] += 1\n",
    "\n",
    "ks_df = pd.DataFrame.from_dict(ks_count, orient = 'Index').sort_values(by=0, ascending = False)\n",
    "\n",
    "ks_pval_df = pd.DataFrame.from_dict(ks_60p_pval)\n",
    "ks_pval_df = ks_pval_df.reset_index().melt('index')\n",
    "ks_pval_df.columns = ['position','odor_cid','pVal']\n",
    "#ks_pval_df.to_csv(\"./mouseOR_alignment/ks_pval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"./mouseOR_alignment/mouseOR_60p_aaIdentity.fasta\",'w') as f:\n",
    "#    for olfr in fasta_60p_aaIdentity:\n",
    "#        f.write('>{0}\\n{1}\\n'.format(olfr, fasta_60p_aaIdentity[olfr]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
