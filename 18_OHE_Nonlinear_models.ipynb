{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6443ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230106f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_resp = pd.read_csv(\"./compiled_desc_resp/compiled_odor_sigResp_wide.csv\", index_col = 0)\n",
    "input_desc = pd.read_csv(\"./ohe_features/optimized_desc_svc_ohe.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1224bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate distances between features\n",
    "def feature_distances(input_vector):\n",
    "    modified_vector = input_vector.reshape(-1,1)\n",
    "    vector_distances = pdist(modified_vector, 'euclidean')\n",
    "    return vector_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ef1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_odors = pd.read_csv(\"./ohe_features/shuffle_optimized_desc_svc_ohe.csv\", index_col = 0)\n",
    "resampled_odors.columns = input_desc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b69d0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to numpy for faster processing\n",
    "input_desc_arr = np.array(input_desc)\n",
    "input_resp_arr = np.array(input_resp)\n",
    "resampled_odors_arr = np.array(resampled_odors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_predictions = pd.DataFrame()\n",
    "#\n",
    "#for i, (o1, o2) in enumerate(itertools.combinations(range(input_desc.shape[0]), 2)):\n",
    "#    print(i)\n",
    "#    temp_predictions = pd.DataFrame()\n",
    "#    #Setup/reset models\n",
    "#    Euc_model = xgb.XGBRegressor(random_state = 42, n_jobs = -1)\n",
    "#    cor_model = xgb.XGBRegressor(random_state = 42, n_jobs = -1)\n",
    "#    cos_model = xgb.XGBRegressor(random_state = 42, n_jobs = -1)\n",
    "#    #Setup testing data\n",
    "#    x_test = input_desc_arr[[o1,o2]]\n",
    "#    shuffle_test = resampled_odors_arr[[o1,o2]]\n",
    "#    y_test = input_resp_arr[[o1,o2]]\n",
    "#    #Setup training data\n",
    "#    x_train = np.delete(input_desc_arr, [o1,o2], axis = 0)\n",
    "#    y_train = np.delete(input_resp_arr, [o1,o2], axis = 0)\n",
    "#    #Scale response data\n",
    "#    resp_scaler = StandardScaler()\n",
    "#    resp_scaler.fit(y_train)\n",
    "#    norm_y_train = resp_scaler.transform(y_train)\n",
    "#    norm_y_test = resp_scaler.transform(y_test)\n",
    "#    #Scale descriptor data\n",
    "#    desc_scaler = StandardScaler()\n",
    "#    desc_scaler.fit(x_train)\n",
    "#    norm_x_train = desc_scaler.transform(x_train)\n",
    "#    norm_x_test = desc_scaler.transform(x_test)\n",
    "#    norm_shuffle_test = desc_scaler.transform(shuffle_test)\n",
    "#    #Calculate descriptor distances in train and test set\n",
    "#    x_train_dist = np.apply_along_axis(func1d = feature_distances, axis = 0, arr=norm_x_train)\n",
    "#    x_test_dist = np.apply_along_axis(func1d = feature_distances, axis = 0, arr=norm_x_test)\n",
    "#    shuffle_test_dist = np.apply_along_axis(func1d = feature_distances, axis = 0, arr=norm_shuffle_test)\n",
    "#    #Calculate response distances\n",
    "#    y_train_Euc_dist = pdist(norm_y_train, 'euclidean')\n",
    "#    y_test_Euc_dist = pdist(norm_y_test, 'euclidean')\n",
    "#    #Calculate correlation response distances\n",
    "#    y_train_cor_dist = pdist(norm_y_train, 'correlation')\n",
    "#    y_test_cor_dist = pdist(norm_y_test, 'correlation')\n",
    "#    #Calculate cosine response distances\n",
    "#    y_train_cos_dist = pdist(norm_y_train, 'cosine')\n",
    "#    y_test_cos_dist = pdist(norm_y_test, 'cosine')\n",
    "#    #Fit models\n",
    "#    Euc_model.fit(x_train_dist, y_train_Euc_dist)\n",
    "#    cor_model.fit(x_train_dist, y_train_cor_dist)\n",
    "#    cos_model.fit(x_train_dist, y_train_cos_dist)\n",
    "#    #Use models to predict intact distances\n",
    "#    ypred_Euc = Euc_model.predict(x_test_dist)\n",
    "#    ypred_cor = cor_model.predict(x_test_dist)\n",
    "#    ypred_cos = cos_model.predict(x_test_dist)\n",
    "#    #Use models to predict shuffled distances\n",
    "#    ypred_Euc_shuffled = Euc_model.predict(shuffle_test_dist)\n",
    "#    ypred_cor_shuffled = cor_model.predict(shuffle_test_dist)\n",
    "#    ypred_cos_shuffled = cos_model.predict(shuffle_test_dist)\n",
    "#    #Compile predictions\n",
    "#    temp_predictions = pd.concat([pd.DataFrame(y_test_Euc_dist),\n",
    "#                                  pd.DataFrame(y_test_cor_dist),\n",
    "#                                  pd.DataFrame(y_test_cos_dist),\n",
    "#                                  pd.DataFrame(ypred_Euc),\n",
    "#                                  pd.DataFrame(ypred_cor),\n",
    "#                                  pd.DataFrame(ypred_cos),\n",
    "#                                  pd.DataFrame(ypred_Euc_shuffled),\n",
    "#                                  pd.DataFrame(ypred_cor_shuffled),\n",
    "#                                  pd.DataFrame(ypred_cos_shuffled)],\n",
    "#                                  axis = 1)\n",
    "#    xgb_predictions = pd.concat([xgb_predictions, temp_predictions], axis = 0)\n",
    "#    \n",
    "#    \n",
    "#xgb_predictions.columns = ['ytrue_Euc','ytrue_cor','ytrue_cos',\n",
    "#                           'ypred_Euc','ypred_cor','ypred_cos',\n",
    "#                           'ypred_Euc_shuffled','ypred_cor_shuffled','ypred_cos_shuffled'\n",
    "#                           ]\n",
    "#\n",
    "##Create new models for full fitting evaluation\n",
    "#Euc_model = xgb.XGBRegressor(random_state = 42, n_jobs = -1)\n",
    "#cor_model = xgb.XGBRegressor(random_state = 42, n_jobs = -1)\n",
    "#cos_model = xgb.XGBRegressor(random_state = 42, n_jobs = -1)\n",
    "##Normalize response data\n",
    "#full_resp_scaler = StandardScaler()\n",
    "#full_resp_scaler.fit(input_resp_arr)\n",
    "#norm_input_resp_arr = full_resp_scaler.transform(input_resp_arr)\n",
    "##Normalize descriptor data\n",
    "#full_desc_scaler = StandardScaler()\n",
    "#full_desc_scaler.fit(input_desc_arr)\n",
    "#norm_input_desc_arr = full_desc_scaler.transform(input_desc_arr)\n",
    "##Calculate full fit response distances\n",
    "#input_resp_arr_Euc_dist = pdist(norm_input_resp_arr, 'euclidean')\n",
    "#input_resp_arr_cor_dist = pdist(norm_input_resp_arr, 'correlation')\n",
    "#input_resp_arr_cos_dist = pdist(norm_input_resp_arr, 'cosine')\n",
    "##Calculate full fit feature Euclidean distances\n",
    "#norm_input_desc_arr_dist = np.apply_along_axis(func1d = feature_distances, axis = 0, arr=norm_input_desc_arr)\n",
    "##Fit models\n",
    "#Euc_model.fit(norm_input_desc_arr_dist, input_resp_arr_Euc_dist)\n",
    "#cor_model.fit(norm_input_desc_arr_dist, input_resp_arr_cor_dist)\n",
    "#cos_model.fit(norm_input_desc_arr_dist, input_resp_arr_cos_dist)      \n",
    "##Use full fit models to make predictions\n",
    "#full_fit_pred_Euc = pd.DataFrame(Euc_model.predict(norm_input_desc_arr_dist))\n",
    "#full_fit_pred_cor = pd.DataFrame(cor_model.predict(norm_input_desc_arr_dist))\n",
    "#full_fit_pred_cos = pd.DataFrame(cos_model.predict(norm_input_desc_arr_dist))\n",
    "##Compile full fit\n",
    "#full_fit_out = pd.concat([input_resp_arr_Euc_dist,\n",
    "#                          input_resp_arr_cor_dist,\n",
    "#                          input_resp_arr_cos_dist,\n",
    "#                          full_fit_pred_Euc,\n",
    "#                          full_fit_pred_cor,\n",
    "#                          full_fit_pred_cos], axis = 1)\n",
    "#full_fit_out.columns = ['fullFit_ytrue_Euc','fullFit_ytrue_cor','fullFit_ytrue_cos',\n",
    "#                        'fullFit_ypred_Euc','fullFit_ypred_cor','fullFit_ypred_cos']\n",
    "#\n",
    "##Save files\n",
    "#xgb_predictions.to_csv(\"./ohe_features/xgb_LOOCV_allDesc_variousMetrics.csv\")\n",
    "#full_fit_out.to_csv(\"./ohe_features/xgb_fullFit_allDesc_variousMetrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edbd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f68564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d1272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6955790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015e58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b7b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b20dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
