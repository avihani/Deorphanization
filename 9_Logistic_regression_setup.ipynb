{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "1.20.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import statistics\n",
    "\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(fastafile):\n",
    "    \"\"\"\n",
    "    Input: FASTA file of aligned Olfr (gaps OK)\n",
    "           entries must start with '>' & sequence must be immediately next\n",
    "           no other lines allowed\n",
    "    Output: dictionary with keys equal identity of entry\n",
    "            values are aa sequence associated with entry \n",
    "    \"\"\"\n",
    "    fasta_dict = {}\n",
    "    header = ''\n",
    "    sequence = ''\n",
    "    with open(fastafile, 'r') as f:\n",
    "        for line in f:\n",
    "            if '>' in line:\n",
    "                if sequence != '':\n",
    "                    fasta_dict[header] = sequence\n",
    "                header = line[1:].strip('\\n')\n",
    "                sequence = ''\n",
    "            else: \n",
    "                sequence += line.strip('\\n')\n",
    "        fasta_dict[header] = sequence\n",
    "    return fasta_dict\n",
    "\n",
    "def parse_fasta(fasta_dict):\n",
    "    \"\"\"\n",
    "    Input: FASTA dict with key:value = gene:sequence\n",
    "    Output: FASTA dict with key:key:value = gene:position:amino acid\n",
    "    \"\"\"\n",
    "    dict_out = {}\n",
    "    for entry in fasta_dict:\n",
    "        dict_out[entry] = {}\n",
    "        seq_len = len(fasta_dict[entry])\n",
    "        for i in range(seq_len):\n",
    "            dict_out[entry][i] = fasta_dict[entry][i]\n",
    "    return dict_out\n",
    "\n",
    "def fasta_prop_calc(fasta_df, grantham_dict):\n",
    "    df_out = pd.DataFrame()\n",
    "    for position in fasta_df.columns:\n",
    "        c_list = []\n",
    "        p_list = []\n",
    "        v_list = []\n",
    "        for gene in fasta_df[position].index:\n",
    "            aa = fasta_df[position].loc[gene]\n",
    "            if aa == '-':\n",
    "                c_list.append('-')\n",
    "                p_list.append('-')\n",
    "                v_list.append('-')\n",
    "            else:\n",
    "                c_list.append(grantham_dict[aa]['c'])\n",
    "                p_list.append(grantham_dict[aa]['p'])\n",
    "                v_list.append(grantham_dict[aa]['v'])\n",
    "        c_series = pd.Series(c_list, name='c_'+str(position+1))\n",
    "        p_series = pd.Series(p_list, name='p_'+str(position+1))\n",
    "        v_series = pd.Series(v_list, name='v_'+str(position+1))\n",
    "        df_out = pd.concat([df_out, c_series], axis = 1)\n",
    "        df_out = pd.concat([df_out, p_series], axis = 1)\n",
    "        df_out = pd.concat([df_out, v_series], axis = 1)\n",
    "    df_out.index = fasta_df.index\n",
    "    return df_out\n",
    "\n",
    "def impute_colmeans(grantham_df):\n",
    "    grantham_noNaN = pd.DataFrame()\n",
    "    for col_id in grantham_df.columns:\n",
    "        grantham_noNaN[col_id] = pd.to_numeric(grantham_df[col_id], errors ='coerce')\n",
    "        col_means = grantham_noNaN[col_id].mean()\n",
    "        grantham_noNaN[col_id] = grantham_noNaN[col_id].fillna(col_means)\n",
    "    return grantham_noNaN\n",
    "\n",
    "def feature_distances(input_vector):\n",
    "    modified_vector = np.array(input_vector).reshape(-1,1)\n",
    "    vector_distances = pdist(modified_vector, 'euclidean')\n",
    "    vector_distances = pd.Series(vector_distances)\n",
    "    return vector_distances\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - x.mean())/(x - x.mean()).std()\n",
    "\n",
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "     \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    " \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_60p_aaIdentity = read_fasta(\"./mouseOR_alignment/mouseOR_60p_aaIdentity.fasta\")\n",
    "fasta_60p_aaIdentity = parse_fasta(fasta_60p_aaIdentity)\n",
    "fasta_60p_aaIdentity = pd.DataFrame.from_dict(fasta_60p_aaIdentity, orient = 'index')\n",
    "fasta_60p_aaIdentity.columns = range(1, fasta_60p_aaIdentity.shape[1]+1, 1)\n",
    "fasta_60p_aaIdentity_dummies = pd.get_dummies(fasta_60p_aaIdentity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps6_dir = \"./olfr_de/\"\n",
    "\n",
    "filename_cid = pd.read_csv(\"./cid_info/filename_cid.csv\", index_col = 0)\n",
    "filename_cid = filename_cid.to_dict(orient='index')\n",
    "\n",
    "for filename in filename_cid:\n",
    "    filename_cid[filename]['cid'] = str(filename_cid[filename]['cid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "odor_test_count = {}\n",
    "\n",
    "for base_name in filename_cid:\n",
    "    split_name = base_name.split('_')[2:]\n",
    "    odor_name = split_name[1].split('.')[0]\n",
    "    if odor_name not in odor_test_count:\n",
    "        odor_test_count[odor_name] = 0\n",
    "    odor_test_count[odor_name] += 1\n",
    "    \n",
    "multi_conc_tested = {}\n",
    "\n",
    "for ps6ip_file in os.listdir(ps6_dir):\n",
    "    conc_odor = ps6ip_file.split('_')[2:]\n",
    "    conc = conc_odor[0]\n",
    "    odor_name = conc_odor[1].split('.')[0]\n",
    "    if odor_test_count[odor_name] > 1:\n",
    "        ps6ip_file = os.path.join(ps6_dir, ps6ip_file)\n",
    "        df = pd.read_csv(ps6ip_file, index_col = 0)\n",
    "        if odor_name not in multi_conc_tested:\n",
    "            multi_conc_tested[odor_name] = {}\n",
    "        multi_conc_tested[odor_name][conc] = df\n",
    "\n",
    "multi_conc_activation = {}\n",
    "\n",
    "for odor in multi_conc_tested:\n",
    "    if odor not in multi_conc_activation:\n",
    "        multi_conc_activation[odor] = {}\n",
    "    for conc in multi_conc_tested[odor]:\n",
    "        df = multi_conc_tested[odor][conc]\n",
    "        sig_or_count = df[(df.logFC > 0) & (df.FDR < 0.05)].shape[0]\n",
    "        if sig_or_count < 8:\n",
    "            continue\n",
    "        multi_conc_activation[odor][conc] = sig_or_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested_resp = {}\n",
    "#sigOR_dict = {}\n",
    "#\n",
    "#for odor in odor_test_count:\n",
    "#    #Pick out concentration for odors tested at multiple concentrations\n",
    "#    if odor_test_count[odor] > 1:\n",
    "#        fewest_or_conc = min(multi_conc_activation[odor], key=multi_conc_activation[odor].get)\n",
    "#        filename = \"pS6_DE_\"+fewest_or_conc+\"_\"+odor+\".csv\"\n",
    "#    else:\n",
    "#    #Rest which are tested at a single concentration\n",
    "#        for base_file in os.listdir(ps6_dir):\n",
    "#            odor_name = base_file.split('_')[3].split('.')[0]\n",
    "#            if odor == odor_name:\n",
    "#                filename = base_file\n",
    "#    file_path = os.path.join(ps6_dir, filename)\n",
    "#    cid = str(filename_cid[filename]['cid'])\n",
    "#    df = pd.read_csv(file_path, index_col = 0)\n",
    "#    df = df.loc[:,['symbol','logFC','FDR']]\n",
    "#    df = df.sort_values(by=['symbol'])\n",
    "#    df = df.reset_index(drop=True)\n",
    "#    #Set criteria for determining significant response\n",
    "#    sigOR_count = df[(df.logFC > 0) & (df.FDR < 0.05)].shape[0]\n",
    "#    if sigOR_count == 0:\n",
    "#        continue\n",
    "#    sigOR_dict[odor] = sigOR_count\n",
    "#    #Set criteria for determining non-significant response\n",
    "#    df.columns = df.columns+\"_\"+cid\n",
    "#    tested_resp[cid] = df\n",
    "##Determine mean & stdev of number of responsive receptors per odor\n",
    "#resp_dist = []\n",
    "#for odor in sigOR_dict:\n",
    "#    resp_dist.append(sigOR_dict[odor])\n",
    "#resp_cutoff = statistics.mean(resp_dist)+(5*statistics.stdev(resp_dist))\n",
    "##Initialize response df        \n",
    "#response_df = pd.DataFrame()\n",
    "##Compile dictionary into logFC df\n",
    "#for cid in tested_resp:\n",
    "#    df = tested_resp[cid]\n",
    "#    if df[(df.iloc[:,1]>0) & (df.iloc[:,2]<0.05)].shape[0] > resp_cutoff:\n",
    "#        continue\n",
    "#    df[cid] = 0\n",
    "#    df.iloc[(df.iloc[:,1]>0) & (df.iloc[:,2]<0.05),3] = 1\n",
    "#    response_df = pd.concat([response_df, df.iloc[:,3]], axis=1)\n",
    "#response_df.index = df.iloc[:,0].values\n",
    "#response_df = response_df.loc[-(response_df.var(axis = 1) == 0),:]\n",
    "#response_df = response_df.loc[:,-(response_df.sum(axis = 0) < 8)]\n",
    "#response_df = response_df.transpose()\n",
    "#response_df.to_csv(\"./mouseOR_alignment/binary_odor_response.csv\")\n",
    "response_df = pd.read_csv(\"./mouseOR_alignment/binary_odor_response.csv\", index_col = 0)\n",
    "response_df = response_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasta_60p_aaIdentity_dummies = fasta_60p_aaIdentity_dummies.loc[fasta_60p_aaIdentity_dummies.index.isin(response_df.index),:]\n",
    "#fasta_60p_aaIdentity_dummies = fasta_60p_aaIdentity_dummies.loc[:,-(fasta_60p_aaIdentity_dummies.var(axis = 0) == 0)]\n",
    "#fasta_60p_aaIdentity_dummies = fasta_60p_aaIdentity_dummies.reindex(response_df.index)\n",
    "#fasta_60p_aaIdentity_dummies = fasta_60p_aaIdentity_dummies.transpose()\n",
    "#fasta_60p_aaIdentity_dummies.to_csv(\"./mouseOR_alignment/fasta_60p_aaIdentity_dummies.csv\")\n",
    "fasta_60p_aaIdentity_dummies = pd.read_csv(\"./mouseOR_alignment/fasta_60p_aaIdentity_dummies.csv\", index_col = 0)\n",
    "fasta_60p_aaIdentity_dummies = fasta_60p_aaIdentity_dummies.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_60p_aaIdentity = fasta_60p_aaIdentity.loc[fasta_60p_aaIdentity.index.isin(response_df.index),:]\n",
    "fasta_60p_aaIdentity_dict = fasta_60p_aaIdentity.to_dict()\n",
    "\n",
    "aa_frequency = {}\n",
    "\n",
    "for position in fasta_60p_aaIdentity_dict:\n",
    "    aa_list = []\n",
    "    aa_dict = {}\n",
    "    aa_counter = 0\n",
    "    max_aa = ''\n",
    "    for receptor in fasta_60p_aaIdentity_dict[position]:\n",
    "        aa_list.append(fasta_60p_aaIdentity_dict[position][receptor])\n",
    "    for aa in aa_list:\n",
    "        if aa not in aa_dict:\n",
    "            aa_dict[aa] = 0\n",
    "        aa_dict[aa] += 1\n",
    "    for aa in aa_dict:\n",
    "        if aa == '-':\n",
    "            continue\n",
    "        if aa_dict[aa] > aa_counter:\n",
    "            aa_counter = aa_dict[aa]\n",
    "            max_aa = aa\n",
    "    aa_frequency[position] = {}\n",
    "    aa_frequency[position]['aa'] = max_aa\n",
    "    aa_frequency[position]['conserv_percent'] = aa_counter\n",
    "    \n",
    "for position in aa_frequency:\n",
    "    aa_frequency[position]['conserv_percent'] = aa_frequency[position]['conserv_percent']/len(aa_list)*100\n",
    "    \n",
    "aa_frequency = pd.DataFrame.from_dict(aa_frequency, orient='index')\n",
    "#aa_frequency.to_csv(\"./mouseOR_alignment/aa_frequency_conservation.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process logistic regression data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_outcome = pd.read_csv(\"./mouseOR_alignment/log_reg_auroc.csv\", index_col = 0)\n",
    "sig_log_reg = log_reg_outcome[log_reg_outcome['auc_1se'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_aa(input_vector):\n",
    "    input_vector_counts = pd.DataFrame(input_vector.value_counts())\n",
    "    if '-' in input_vector_counts.index:\n",
    "        input_vector_counts = input_vector_counts.drop(['-'])\n",
    "    common_aa = input_vector_counts.index[0]\n",
    "    return(common_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_out = pd.DataFrame()\n",
    "\n",
    "for odor in odor_test_count:\n",
    "    #Pick out concentration for odors tested at multiple concentrations\n",
    "    if odor_test_count[odor] > 1:\n",
    "        fewest_or_conc = min(multi_conc_activation[odor], key=multi_conc_activation[odor].get)\n",
    "        filename = \"pS6_DE_\"+fewest_or_conc+\"_\"+odor+\".csv\"\n",
    "    else:\n",
    "    #Rest which are tested at a single concentration\n",
    "        for base_file in os.listdir(ps6_dir):\n",
    "            odor_name = base_file.split('_')[3].split('.')[0]\n",
    "            if odor == odor_name:\n",
    "                filename = base_file\n",
    "    cid = filename_cid[filename]['cid']\n",
    "    if int(cid) not in sig_log_reg['cid'].values:\n",
    "        continue\n",
    "    input_df = pd.read_csv(os.path.join(\"./olfr_de\",filename), index_col = 0)\n",
    "    #Drop odors without at least 8 activated ORs or > 3 std devs\n",
    "    sig_responders = input_df[(input_df.logFC > 0) & (input_df.FDR < 0.05)]\n",
    "    if (sig_responders.shape[0] < 8) | (sig_responders.shape[0] > resp_cutoff):\n",
    "        continue\n",
    "    sig_olfr_aa = fasta_60p_aaIdentity.loc[sig_responders['symbol'].values,:]\n",
    "    most_common_aa = pd.DataFrame(sig_olfr_aa.apply(find_common_aa))\n",
    "    most_common_aa.columns = ['text']\n",
    "    most_common_aa['position'] = most_common_aa.index\n",
    "    most_common_aa['cid'] = cid\n",
    "    most_common_aa['odor'] = odor\n",
    "    most_common_aa['filename'] = filename\n",
    "    log_reg_out = pd.concat([log_reg_out, most_common_aa])\n",
    "    with open(\"./fasta_files/\"+odor+\".fasta\", \"w\") as fasta_out:\n",
    "        for sig_olfr in sig_responders['symbol']:\n",
    "            olfr_string = ''.join(fasta_60p_aaIdentity.loc[sig_olfr,:].values)\n",
    "            fasta_out.write(f'>{sig_olfr}\\n')\n",
    "            fasta_out.write(f'{olfr_string}\\n')\n",
    "        fasta_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "#log_reg_out = log_reg_out.reset_index(drop=True)\n",
    "#log_reg_out.to_csv(\"./mouseOR_alignment/common_aa_from_logReg.csv\")\n",
    "log_reg_out = pd.read_csv(\"./mouseOR_alignment/common_aa_from_logReg.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pS6 data used for logistic regression compiled into a single CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested_resp = {}\n",
    "#sigOR_dict = {}\n",
    "#\n",
    "#for odor in odor_test_count:\n",
    "#    #Pick out concentration for odors tested at multiple concentrations\n",
    "#    if odor_test_count[odor] > 1:\n",
    "#        fewest_or_conc = min(multi_conc_activation[odor], key=multi_conc_activation[odor].get)\n",
    "#        filename = \"pS6_DE_\"+fewest_or_conc+\"_\"+odor+\".csv\"\n",
    "#    else:\n",
    "#    #Rest which are tested at a single concentration\n",
    "#        for base_file in os.listdir(ps6_dir):\n",
    "#            odor_name = base_file.split('_')[3].split('.')[0]\n",
    "#            if odor == odor_name:\n",
    "#                filename = base_file\n",
    "#    file_path = os.path.join(ps6_dir, filename)\n",
    "#    cid = str(filename_cid[filename]['cid'])\n",
    "#    df = pd.read_csv(file_path, index_col = 0)\n",
    "#    #Set criteria for determining significant response\n",
    "#    sigOR_count = df[(df.logFC > 0) & (df.FDR < 0.05)].shape[0]\n",
    "#    if sigOR_count == 0:\n",
    "#        continue\n",
    "#    sigOR_dict[odor] = sigOR_count\n",
    "#    #Set criteria for determining non-significant response\n",
    "#    df['cid'] = cid\n",
    "#    tested_resp[cid] = df\n",
    "#    \n",
    "##Determine mean & stdev of number of responsive receptors per odor\n",
    "#resp_dist = []\n",
    "#for odor in sigOR_dict:\n",
    "#    resp_dist.append(sigOR_dict[odor])\n",
    "#resp_cutoff = statistics.mean(resp_dist)+(5*statistics.stdev(resp_dist))\n",
    "#\n",
    "##Initialize response df        \n",
    "#response_df = pd.DataFrame()\n",
    "##Loop through to compile\n",
    "#for cid in tested_resp:\n",
    "#    df = tested_resp[cid]\n",
    "#    if df[(df['logFC'] > 0) & (df['FDR'] < 0.05)].shape[0] > resp_cutoff:\n",
    "#        continue\n",
    "#    response_df = pd.concat([response_df, df])\n",
    "#    \n",
    "#response_df = response_df.reset_index(drop = True)\n",
    "#response_df.to_csv(\"compiled_desc_resp/log_reg_compiled_ps6_data.csv\")\n",
    "response_df = pd.read_csv(\"compiled_desc_resp/log_reg_compiled_ps6_data.csv\", index_col = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
